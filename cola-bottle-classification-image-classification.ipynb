{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi all. In this notebook, I'll try to address the different image classification algorithms. I'll be working with a cola bottle dataset, which contains over 6500+ images segregated into 8 different classes. My approach is to make a comparitive study between custom CNN models and Transfer Learning models and check which would give the best accuracy.\n\nIf you like it, please upvote, and if you don't, please drop a comment, I would love to learn from my mistakes. Cheers! Let's get started! ","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing\n\nBefore, we jump into the image classification algorithms, our preliminary step would be to preprocess the data. The data is in the form of images, we need to convert it to an array of vectors which would be given as input to the model for a prediction.","metadata":{}},{"cell_type":"markdown","source":"**Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras import backend as K\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Model, Sequential\nfrom keras.applications import imagenet_utils\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import Image\nfrom keras.optimizers import Adam\nfrom keras.layers import GlobalMaxPooling2D, Conv2D, MaxPooling2D, Flatten, Bidirectional, SpatialDropout2D, Input, Dropout\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2021-06-15T11:58:03.910323Z","iopub.execute_input":"2021-06-15T11:58:03.910799Z","iopub.status.idle":"2021-06-15T11:58:11.989585Z","shell.execute_reply.started":"2021-06-15T11:58:03.910707Z","shell.execute_reply":"2021-06-15T11:58:11.988481Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing the data**\n\nBasically, I'm creating a function where I'll be taking the input file as an argument, and I'd be converting the image to a numpy array using the inbuilt function **load_img** from **keras.preprocessing.image**","metadata":{}},{"cell_type":"code","source":"def prepare_image(file):\n    #img_path = './practical example/'\n    img = image.load_img(file, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T11:58:11.990843Z","iopub.execute_input":"2021-06-15T11:58:11.991129Z","iopub.status.idle":"2021-06-15T11:58:11.997156Z","shell.execute_reply.started":"2021-06-15T11:58:11.991102Z","shell.execute_reply":"2021-06-15T11:58:11.995819Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n\nX_train=X.flow_from_directory('../input/cola-bottle-identification/Soda Bottles',\n                                                 target_size=(224,224),\n                                                 color_mode='rgb',\n                                                 batch_size=320,\n                                                 class_mode='categorical',\n                                                 shuffle=True)\nlabel_map = (X_train.class_indices)\ny=[]\nfor i in label_map:\n    y.append(i)\ny_categorical = pd.get_dummies(y)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T11:58:11.998990Z","iopub.execute_input":"2021-06-15T11:58:11.999287Z","iopub.status.idle":"2021-06-15T11:58:12.660432Z","shell.execute_reply.started":"2021-06-15T11:58:11.999258Z","shell.execute_reply":"2021-06-15T11:58:12.659345Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 6615 images belonging to 8 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"CNN_Model1 = Sequential()\nCNN_Model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3)))\nCNN_Model1.add(MaxPooling2D(pool_size=(2, 2)))\nCNN_Model1.add(Dropout(0.2))\n\nCNN_Model1.add(Flatten())\n\nCNN_Model1.add(Dense(128, activation='relu'))\nCNN_Model1.add(Dense(8, activation='softmax'))\nCNN_Model1.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T11:58:12.662009Z","iopub.execute_input":"2021-06-15T11:58:12.662323Z","iopub.status.idle":"2021-06-15T11:58:13.201726Z","shell.execute_reply.started":"2021-06-15T11:58:12.662291Z","shell.execute_reply":"2021-06-15T11:58:13.200687Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 222, 222, 32)      896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n_________________________________________________________________\ndropout (Dropout)            (None, 111, 111, 32)      0         \n_________________________________________________________________\nflatten (Flatten)            (None, 394272)            0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               50466944  \n_________________________________________________________________\ndense_1 (Dense)              (None, 8)                 1032      \n=================================================================\nTotal params: 50,468,872\nTrainable params: 50,468,872\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"CNN_Model1.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\nstep_size_train=X_train.n//X_train.batch_size\nCNN_Model1.fit(X_train,\n                   steps_per_epoch=step_size_train,\n                epochs=5)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T11:58:13.203071Z","iopub.execute_input":"2021-06-15T11:58:13.203403Z","iopub.status.idle":"2021-06-15T12:12:37.148426Z","shell.execute_reply.started":"2021-06-15T11:58:13.203369Z","shell.execute_reply":"2021-06-15T12:12:37.147231Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/5\n20/20 [==============================] - 172s 8s/step - loss: 19.0461 - accuracy: 0.1757\nEpoch 2/5\n20/20 [==============================] - 183s 9s/step - loss: 1.3059 - accuracy: 0.5248\nEpoch 3/5\n20/20 [==============================] - 169s 8s/step - loss: 0.7251 - accuracy: 0.8269\nEpoch 4/5\n20/20 [==============================] - 167s 8s/step - loss: 0.4501 - accuracy: 0.9295\nEpoch 5/5\n20/20 [==============================] - 168s 8s/step - loss: 0.2977 - accuracy: 0.9645\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fc9aa969b90>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Transfer Learning\n\n> *Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.*\n","metadata":{}},{"cell_type":"markdown","source":"**MobileNet**\n\nSo, I'll be importing the MobileNet model with pretrained weights 'imagenet' and retrain the top layers with my input dataset. I'll keep the layers very limited and simple initially, and would add more layers if required.\n\nI've used ImageDataGenerator function, whose task is to generate a dataset from image files. So, my X or dependent feature will be the preprocessed image dataset, and the target variable (y) will be the classes.","metadata":{}},{"cell_type":"code","source":"MobileNet_model = keras.applications.mobilenet.MobileNet()\nMobileNet_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n\nx=MobileNet_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\nx=Dense(1024,activation='relu')(x) #dense layer 2\nx=Dense(512,activation='relu')(x) #dense layer 3\npreds=Dense(8,activation='softmax')(x) #final layer with softmax activation\n\nMobileNet_model=Model(inputs=MobileNet_model.input,outputs=preds)\n\nfor layer in MobileNet_model.layers:\n    layer.trainable=False\n# or if we want to set the first 20 layers of the network to be non-trainable\nfor layer in MobileNet_model.layers[:20]:\n    layer.trainable=False\nfor layer in MobileNet_model.layers[20:]:\n    layer.trainable=True\n\n\nMobileNet_model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n# Adam optimizer\n# loss function will be categorical cross entropy\n# evaluation metric will be accuracy\n\nstep_size_train=X_train.n//X_train.batch_size\nMobileNet_model.fit(X_train,\n                   steps_per_epoch=step_size_train,\n                epochs=5)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:12:37.150560Z","iopub.execute_input":"2021-06-15T12:12:37.151042Z","iopub.status.idle":"2021-06-15T13:01:36.014973Z","shell.execute_reply.started":"2021-06-15T12:12:37.150994Z","shell.execute_reply":"2021-06-15T13:01:36.011961Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n17227776/17225924 [==============================] - 1s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n17227776/17225924 [==============================] - 1s 0us/step\nEpoch 1/5\n20/20 [==============================] - 592s 29s/step - loss: 1.6039 - accuracy: 0.4996\nEpoch 2/5\n20/20 [==============================] - 583s 29s/step - loss: 0.1158 - accuracy: 0.9524\nEpoch 3/5\n20/20 [==============================] - 593s 30s/step - loss: 0.0140 - accuracy: 0.9959\nEpoch 4/5\n20/20 [==============================] - 586s 29s/step - loss: 0.0304 - accuracy: 0.9924\nEpoch 5/5\n20/20 [==============================] - 578s 29s/step - loss: 0.0108 - accuracy: 0.9975\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fc990415150>"},"metadata":{}}]}]}